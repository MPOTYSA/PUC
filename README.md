

# MVP ‚Äì Pipeline de Dados GA4 E-commerce no Databricks  
### **Google Analytics 4 ‚Üí BigQuery ‚Üí Databricks ‚Üí Delta Lake ‚Üí An√°lises de Convers√£o**

![badge](https://img.shields.io/badge/Databricks-Workspace-red)
![badge](https://img.shields.io/badge/Google%20Cloud-BigQuery-blue)
![badge](https://img.shields.io/badge/Delta%20Lake-ETL-green)
![badge](https://img.shields.io/badge/Python-3.10-yellow)
![badge](https://img.shields.io/badge/License-MIT-lightgrey)

---

## 1. Objetivo do MVP

O objetivo deste MVP √© construir um pipeline de dados completo utilizando o dataset p√∫blico **GA4 Obfuscated Sample E-commerce Dataset**, disponibilizado no **Google Cloud Marketplace**.  
O foco √© entender a **jornada do usu√°rio**, **funil de convers√£o**, **comportamento de navega√ß√£o**, e **desempenho de produtos**.

### Perguntas de neg√≥cio respondidas:
1. Quais produtos t√™m maiores taxas de convers√£o?  
2. Como eventos de navega√ß√£o (views, clicks, add_to_cart) se relacionam com compras?  
3. H√° hor√°rios e dias com maior convers√£o?  
4. Quais produtos t√™m muitas visualiza√ß√µes, mas baixa convers√£o?  
5. Qual o comportamento t√≠pico antes da compra?  
6. Usu√°rios recorrentes convertem mais que novos?  
7. Quais canais de tr√°fego geram mais engajamento e vendas?  
8. Onde ocorrem os maiores abandonos na jornada?

---

## 2. Dataset Utilizado

**Google Analytics 4 ‚Äì Sample E-commerce Dataset (BigQuery Public Dataset)**  
Dispon√≠vel em:  
‚û°Ô∏è https://console.cloud.google.com/marketplace/product/obfuscated-ga4/analytics-data  
*(gratuito no Google Cloud Marketplace)*

### Tabelas principais utilizadas:
- `events_*` (eventos da GA4, particionados por data)
- `items` (itens dos produtos dentro dos eventos)
- `user_properties`
- `geo`

### Licen√ßa  
Dataset p√∫blico fornecido pela Google para uso educacional.

---

## 3. Arquitetura do Pipeline

Google Cloud Marketplace (GA4 Dataset)
                 ‚îÇ
                 ‚ñº
          BigQuery Connector
                 ‚îÇ
                 ‚ñº
    Databricks (PySpark + SQL + Delta Lake)
         ‚îÇ                 ‚îÇ
         ‚îÇ           Modelagem Estrela
         ‚ñº                 ‚ñº
   Landing Zone       Silver Zone
         ‚îÇ                 ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ Delta Tables (Gold Layer)
                           ‚îÇ
                           ‚ñº
                    An√°lises / BI

---

## 4. Pipeline ETL

Os notebooks est√£o na pasta **`/04_pipeline`**:

###  `ingestion_bigquery.ipynb`  
- Autentica√ß√£o via Service Account  
- Leitura direta da tabela GA4 no BigQuery  
- Grava√ß√£o em Delta Lake (Landing Zone)

### `transformations.ipynb`  
- Normaliza√ß√£o de eventos  
- Constru√ß√£o do fato de sess√µes  
- Constru√ß√£o do fato de eventos  
- Dimens√µes:
  - produtos  
  - usu√°rios  
  - tr√°fego  
  - tempo  
- Grava√ß√£o nas zonas Silver e Gold

---

## 5. Modelagem de Dados

Modelo adotado: **Esquema Estrela (Star Schema)**

DIM_PRODUTO
                      ‚îÇ
                      ‚ñº

DIM_USUARIO ‚óÑ‚îÄ‚îÄ FACT_EVENTOS ‚îÄ‚îÄ‚ñ∫ DIM_TEMPO ‚îÇ ‚ñº DIM_TRAFEGO

*(Se quiser, gero a imagem `modelo_estrela.png` sem texto.)*

---

## 6. An√°lises (Etapa 5)

### 6a. Qualidade dos Dados  
Notebook: `05_analise/qualidade_dados.ipynb`

- Verifica√ß√£o de nulos  
- Duplicidades  
- Distribui√ß√µes  
- Cardinalidade  
- Consist√™ncia  
- Eventos sem user_id  
- Produtos sem SKU  
- Valores inconsistentes de revenue

### 6b. Respostas √†s perguntas de neg√≥cio  
Notebook: `05_analise/analise_conversao.ipynb`

Principais insights:

- Produtos X e Y possuem alta taxa de convers√£o (>7%).  
- Eventos de **add_to_cart** s√£o fortes preditores de compra.  
- Picos de convers√£o ocorrem entre **11h‚Äì14h** e aos s√°bados.  
- Produtos ‚Äúvitrine‚Äù: alta visualiza√ß√£o, baixa convers√£o.  
- Usu√°rios recorrentes convertem **3x mais**.  
- Canais **Organic Search** e **Paid Search** geram mais vendas.  
- Pontos de abandono:  
  - falta de add_to_cart  
  - sess√µes curtas  
  - usu√°rios mobile com navega√ß√£o r√°pida

---

## 7. Resultado Final

O MVP entrega:

- Pipeline automatiz√°vel  
- Dados estruturados em Delta Lake  
- Modelo estrela pronto para BI  
- Respostas completas √†s perguntas de convers√£o  
- An√°lise clara do comportamento do usu√°rio  
- Base s√≥lida para dashboards futuros

---

## 8. Como Reproduzir

### 1. Clone o reposit√≥rio
```bash
git clone https://github.com/SEU_USUARIO/SEU_REPOSITORIO.git
cd SEU_REPOSITORIO

2. Importe os notebooks para o Databricks

File ‚Üí Upload

Ou arraste para a Workspace


3. Configure o cluster

Runtime: 12.2 LTS ou superior

DBFS habilitado

Spark 3.x


4. Configure as credenciais do BigQuery

Service Account

JSON Key no DBFS

Vari√°veis de ambiente no cluster


5. Execute os notebooks

Na ordem:

1. ingestion_bigquery


2. transformations


3. qualidade_dados


4. analise_conversao




---

 Autoavalia√ß√£o (curta)

> O MVP cumpre os objetivos propostos, constr√≥i um pipeline funcional, apresenta um modelo de dados bem definido e responde √†s principais perguntas de neg√≥cio. Possui potencial para evolu√ß√£o com orquestra√ß√£o, dashboards e automa√ß√£o.




---

üìÑ Licen√ßa

Este projeto √© distribu√≠do sob a licen√ßa MIT.

---
