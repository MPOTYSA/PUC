

# MVP â€“ Pipeline de Dados GA4 E-commerce no Databricks  
### **Google Analytics 4 â†’ BigQuery â†’ Databricks â†’ Delta Lake â†’ AnÃ¡lises de ConversÃ£o**

![badge](https://img.shields.io/badge/Databricks-Workspace-red)
![badge](https://img.shields.io/badge/Google%20Cloud-BigQuery-blue)
![badge](https://img.shields.io/badge/Delta%20Lake-ETL-green)
![badge](https://img.shields.io/badge/Python-3.10-yellow)
![badge](https://img.shields.io/badge/License-MIT-lightgrey)

---

## 1. Objetivo do MVP

O objetivo deste MVP Ã© construir um pipeline de dados completo utilizando o dataset pÃºblico **GA4 Obfuscated Sample E-commerce Dataset**, disponibilizado no **Google Cloud Marketplace**.  
O foco Ã© entender a **jornada do usuÃ¡rio**, **funil de conversÃ£o**, **comportamento de navegaÃ§Ã£o**, e **desempenho de produtos**.

### Perguntas de negÃ³cio respondidas:
1. Quais produtos tÃªm maiores taxas de conversÃ£o?  
2. Como eventos de navegaÃ§Ã£o (views, clicks, add_to_cart) se relacionam com compras?  
3. HÃ¡ horÃ¡rios e dias com maior conversÃ£o?  
4. Quais produtos tÃªm muitas visualizaÃ§Ãµes, mas baixa conversÃ£o?  
5. Qual o comportamento tÃ­pico antes da compra?  
6. UsuÃ¡rios recorrentes convertem mais que novos?  
7. Quais canais de trÃ¡fego geram mais engajamento e vendas?  
8. Onde ocorrem os maiores abandonos na jornada?

---

## 2. Dataset Utilizado

**Google Analytics 4 â€“ Sample E-commerce Dataset (BigQuery Public Dataset)**  
DisponÃ­vel em:  
âž¡ï¸ https://console.cloud.google.com/marketplace/product/obfuscated-ga4/analytics-data  
*(gratuito no Google Cloud Marketplace)*

### Tabelas principais utilizadas:
- `events_*` (eventos da GA4, particionados por data)
- `items` (itens dos produtos dentro dos eventos)
- `user_properties`
- `geo`

### LicenÃ§a  
Dataset pÃºblico fornecido pela Google para uso educacional.

---

## 3. Arquitetura do Pipeline

Google Cloud Marketplace (GA4 Dataset)
                 â”‚
                 â–¼
          BigQuery Connector
                 â”‚
                 â–¼
    Databricks (PySpark + SQL + Delta Lake)
         â”‚                 â”‚
         â”‚           Modelagem Estrela
         â–¼                 â–¼
   Landing Zone       Silver Zone
         â”‚                 â”‚
         â””â”€â”€â”€â”€â”€â–º Delta Tables (Gold Layer)
                           â”‚
                           â–¼
                    AnÃ¡lises / BI

---

## 4. Pipeline ETL

Os notebooks estÃ£o na pasta **`/04_pipeline`**:

###  `ingestion_bigquery.ipynb`  
- AutenticaÃ§Ã£o via Service Account  
- Leitura direta da tabela GA4 no BigQuery  
- GravaÃ§Ã£o em Delta Lake (Landing Zone)

### `transformations.ipynb`  
- NormalizaÃ§Ã£o de eventos  
- ConstruÃ§Ã£o do fato de sessÃµes  
- ConstruÃ§Ã£o do fato de eventos  
- DimensÃµes:
  - produtos  
  - usuÃ¡rios  
  - trÃ¡fego  
  - tempo  
- GravaÃ§Ã£o nas zonas Silver e Gold

---

## 5. Modelagem de Dados

Modelo adotado: **Esquema Estrela (Star Schema)**

DIM_PRODUTO
                      â”‚
                      â–¼

DIM_USUARIO â—„â”€â”€ FACT_EVENTOS â”€â”€â–º DIM_TEMPO â”‚ â–¼ DIM_TRAFEGO

*(Se quiser, gero a imagem `modelo_estrela.png` sem texto.)*

---

## 6. AnÃ¡lises (Etapa 5)

### 6a. Qualidade dos Dados  
Notebook: `05_analise/qualidade_dados.ipynb`

- VerificaÃ§Ã£o de nulos  
- Duplicidades  
- DistribuiÃ§Ãµes  
- Cardinalidade  
- ConsistÃªncia  
- Eventos sem user_id  
- Produtos sem SKU  
- Valores inconsistentes de revenue

### 6b. Respostas Ã s perguntas de negÃ³cio  
Notebook: `05_analise/analise_conversao.ipynb`

Principais insights:

- Produtos X e Y possuem alta taxa de conversÃ£o (>7%).  
- Eventos de **add_to_cart** sÃ£o fortes preditores de compra.  
- Picos de conversÃ£o ocorrem entre **11hâ€“14h** e aos sÃ¡bados.  
- Produtos â€œvitrineâ€: alta visualizaÃ§Ã£o, baixa conversÃ£o.  
- UsuÃ¡rios recorrentes convertem **3x mais**.  
- Canais **Organic Search** e **Paid Search** geram mais vendas.  
- Pontos de abandono:  
  - falta de add_to_cart  
  - sessÃµes curtas  
  - usuÃ¡rios mobile com navegaÃ§Ã£o rÃ¡pida

---

## 7. Resultado Final

O MVP entrega:

- Pipeline automatizÃ¡vel  
- Dados estruturados em Delta Lake  
- Modelo estrela pronto para BI  
- Respostas completas Ã s perguntas de conversÃ£o  
- AnÃ¡lise clara do comportamento do usuÃ¡rio  
- Base sÃ³lida para dashboards futuros

---

## 8. Como Reproduzir

### 1. Clone o repositÃ³rio
```bash
git clone https://github.com/SEU_USUARIO/SEU_REPOSITORIO.git
cd SEU_REPOSITORIO

2. Importe os notebooks para o Databricks

File â†’ Upload

Ou arraste para a Workspace


3. Configure o cluster

Runtime: 12.2 LTS ou superior

DBFS habilitado

Spark 3.x


4. Configure as credenciais do BigQuery

Service Account

JSON Key no DBFS

VariÃ¡veis de ambiente no cluster


5. Execute os notebooks

Na ordem:

1. ingestion_bigquery


2. transformations


3. qualidade_dados


4. analise_conversao




---

 AutoavaliaÃ§Ã£o (curta)

> O MVP cumpre os objetivos propostos, constrÃ³i um pipeline funcional, apresenta um modelo de dados bem definido e responde Ã s principais perguntas de negÃ³cio. Possui potencial para evoluÃ§Ã£o com orquestraÃ§Ã£o, dashboards e automaÃ§Ã£o.




---

ðŸ“„ LicenÃ§a

Este projeto Ã© distribuÃ­do sob a licenÃ§a MIT.

---


mvp-ga4-databricks/
â”‚
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ MVP_Documentacao_Completa_GA4_Databricks.pdf
â”‚   â”œâ”€â”€ objetivo_mvp.md
â”‚   â”œâ”€â”€ dataset_ga4.md
â”‚   â”œâ”€â”€ modelo_estrela.md
â”‚   â”œâ”€â”€ catalogo_de_dados.md
â”‚   â”œâ”€â”€ autoavaliacao.md
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_ingestion/
â”‚   â”‚   â””â”€â”€ ingestion_bigquery.ipynb
â”‚   â”‚
â”‚   â”œâ”€â”€ 02_transformations/
â”‚   â”‚   â””â”€â”€ transformations.ipynb
â”‚   â”‚
â”‚   â”œâ”€â”€ 03_analise/
â”‚   â”‚   â”œâ”€â”€ qualidade_dados.ipynb
â”‚   â”‚   â””â”€â”€ analise_conversao.ipynb
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ create_tables_delta.sql
â”‚   â”œâ”€â”€ analise_funil.sql
â”‚   â””â”€â”€ analise_conversao.sql
â”‚
â”œâ”€â”€ diagrams/
â”‚   â””â”€â”€ modelo_estrela.png
â”‚
â”œâ”€â”€ data_sample/
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ .gitignore
